CHAPTER 2 DATA STRUCTURES

	* Assigning to Slices
		- Apparently my_list[2:4] = [0, 1, 8, 6, 2] is totally valid and works exactly as you would expect
		- del my_list[2:5] is a valid target for delection and works as you would expect

	* Using + and * with sequences
		- l = [1, 2] * 2 generates a list that looks like [1, 2, 1, 2]
		CAUTION: this only does a shallow copy of the list, so if the items are lists themselves this will not work as expected.

	* Augmented Assignment with Sequences
		- += corresponds to the special method __iadd__ or __add__ if the first is not implemented (and it just calls a = a + b directly)
		- putting mutable objects in tuples is not a good idea lol

	* list.sort and the sorted built-in function
		list.sort() modifies the list in place, but sorted() returns an object that has been sorted
		- both take two arguments: key and reverse
		- key is very powerful as it lets you create a 'sorting key' which I would call a 'sorting expression' used to sort by value. key is expected to be a function. An implicit function mapping.
		- functions or methods that modify objects in-place should always return a value of None. Otherwise the functions return the modified object

	* Managing Ordered Sequences with bisect
		- I'm going to ignore this for now and return to it as-needed.
		- bisect.insort(list, item) inserts an item keeping sorting intact.
	
	* When a list isn't the answer: Arrays
		array.array is a more efficient mutable list, and is as lean as an array in C.
		- arrays require a 'typecode', a single-letter code that determines the arrays type. 'b' for signed char, 'f' for 32-bit float, 'd' for double-precision 64-bit float.
		- 'wb' and 'rb' allow us to read and write bytes directly to a file using array.tofile (typical write sequence otherwise)
		- the 'pickle' module also handles complex numbers in a similar way.
	
	* Memory Views
		- the memoryview module allows you to share memory directly like a database or an image without having to copy it.
	
	* NumPy and SciPy
		- oh thank god numpy allows for element-wise operations
		- scipy builds on numpy with algorithms from calculus, statistics, and linear algebra, and uses FORTRAN and C to implement them.
		- array.shape lets you change the shape of a matrix
		- numpy also pretty-prints matrices which is nice
	
	* Dequeues and other queues 
		- dequeues are a really fast way of implementing stacks and FIFOs

CHAPTER 3 DICTIONARIES AND SETS
	* Introduction
		- dicts are optimized using hash tables

	* Generic Mapping Types
		- apparently a dict is also sometimes called a "mapping" b/c it is
		- dictionary keys are hashable
		- to implement a hash you need the hash and eq special methods
		- tuples are not necessarily hashable b/c they can contain references to mutable objects
	
	* dict comprehensions
		- builds a key value pair from an iterable

	* Overview of common mapping methods
		- the defaultdict type creates items on demand when a missing key is requested
		- when initializing a defalut dict you need to pass it the factory function it will use to create things
	
	* The __missing__ method
		- for consistent behavior when you implement __missing__ you should also implement __contains__
		- this essentially lets you parse keys before lookup

	* Variations of dict
		- OrderedDict maintains insertion order
		- ChainMap is obscure AF for metaprogramming and interpreters
		- Counter adds a lookup counter to each key, and updating an existing key adds to the counter
		- UserDict is designed to be subclassed so you can use it

	* Subclassing UserDict
		- we can override the __setitem__, __contains__, __missing__, and really any other special methods we want
		- a little weird in that you need to access its internal dictionary called 'data' to look anything up

	* Immutable Mappings
		- you can use something called a "mapping proxy" as a reference to a dict that cannot actually set anything
		- types.MappingProxyType is actually really simple to use (see p. 78)

	* Set Theory
		- set elements must be hashable, but sets themselves are not
		- frozensets can be used if you want an immutable set
		- set comprehensions are a thing. yay!
		- they support symmetric difference using '^'
		- see page 82, 84 for set operations in python

	* Dict and Set under the hood
		- they are implemented using hash tables
		- objects that compare as equal must have the same hash value, or the algorithm doesn't work by definition
		- if you implement __eq__ you must also implement __hash__ so that dicts and sets can deal with your item, even if it is only to return a TypeError that says 'unhashable'
		- the disadvantage to hash tables is they have a not-insignificant amount of overhead
		- Optimization is the altar where maintainability is sacrificed
		- key lookup is blazingly fast so long as the dict fits in memory
		- adding to a dict may change the ordering of keys (DON'T SEARCH A DICT WHILE ADDING TO IT)
		- JSON is compatible with dicts and basically replaces XML. Fuck XML

CHAPTER 4 TEXT VERSUS BYTES
	* Introduction
		- Unicode string data and binary data are two different things

	* Character Issues
		- The best definition we had for a character circa 2014 is a 'Unicode Character', this is what python3 uses
		- The identity of a unicode character is represented by its 'code point' written as U+1D11EF, 4-6 digit hexadecimal
		- The physical bytes used to represent a unicode character differ based on the encoding used (i.e. UTF-8 or UTF-16LE)
		- str.encode(s, fmt) and str.decode(b, fmt) allow you to translate between unicode representation and the underlying bytes used in a specific encoding

	* Byte Essentials
		- python 3 handles all strings as unicode strings
		- bytes (immutable) and bytearray(mutable) are the two ways of storing arrays of bytes, which can have a value from 0 to 255
		- if you work a lot with binary data, consult the documentation on memory views and structs - Interpret bytes as packed binary data
		- bytes can actually be generates directly from hex strings using bytes.fromhex(str)
		- struct.unpack allows for easy management of fields of bytes and data that is stored in binary form

	* Basic encoders / decoders
		- a "codec" is an encoder/decoder pair, such as 'utf-8' or 'mp3' or 'ascii' or 'latin-1'
		- bytes.fromhex() allows direct conversion from a space-delimited hex string to bytes

	* Understanding encode/decode problems
		- not every byte sequence is valid unicode
		- garbled characters are known as gremilns or mojibake, and look like question marks within squares.
		- unicode decoding has the option to replace garbled characters with question marks, this is what you see when trying to read binary files

	* How to detect the encoding
		- short answer is you can't lol.
		- long answer is use statistics and heuristics to predict it (chardetect in python will do this for you)

	* BOM: A useful gremlin
		- apparently there is often a byte-order-mark (BOM) that tells you whether the produced bytes are big-endian or little-endian
		- this should be automatically filtered by the codec

	* Handling Text Files
		- encoding defaults differ by operating system, NEVER assume an encoding for multi-platform projects. using encoding=whatever when reading and writing from files.

	* Normalizing Unicode
		- Many unicode characters actually have multiple representations, 'NFC' is the recommended form of normalization.
		- some forms of normalization (NFKC and NFKD) involve data loss
	
	* Ignored sections on dealing with other languages

PART 3 FUNCTIONS AS OBJECTS
CHAPTER 5 FIRST-CLASS-FUNCTIONS
	* Functions are first-class objects in python
	* the __doc__ special method gives helptext for programmers of the function. Can be accessed through help(func)

	* Higher Order Functions
		- functions that take functions as argument or return functions as a return value are called "higher order functions"
		- generator expressions and comprehensions basically replace most higher-order functions (but do the same thing at their core)
		- "to use a higher-order function sometimes it is convenient to creat a small, one-off function. That is why anonymous functions exist."

	* Anonymous Functions
		- the lambda keyword creates anonymous functions
		- basically only use them as arguments to higher-order functions

	* The Seven flavors of callable objects
		- () is actually an operator: the call operator.
		- seven types of objects are callable in python

	* User defined callable types
		- implementing a __call__ method in your classes makes them callable, just like functions. This is often useful as a shortcut.
		- dir() gives you all the identifiers/attributes of a function (the variables, functions, and classes defined inside it). The process of calling dir is "function introspection"
		- along with set operations you can use this to see how functions or classes differ from each other

	* From positional to keyword-only parameters
		- for no additional positional arguments but mandatory keyword arguments you can put def f(a, *, kwarg), where kward is a mandatory keyword argument.
		- __defaults__ attribute holds a tuple with default values of positional and keyword arguments
		- __kwdefaults__ holds the keyword-only argument defaults
		- __code__ attribute holds names of arguments of a function
		- dir() is great.
		- function annotationts is a terrible fucking idea. Not using it.

	* Packages for functional programming
		- I'm not gonna inspect this at the moment, will come back when necessary. This is getting into the weeds a bit.

CHAPTER 6 DESIGN PATTERNS WITH FIRST-CLASS FUNCTIONS
	* globals() shows you all the modules and functions in your current environment
